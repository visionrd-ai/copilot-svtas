MODEL:
    backbone:
        pretrained: True
        depth: 50
    neck:
        buffer_channels: 512
        hidden_channels: 64
        num_layers: 5
        num_segs: 15
        clip_buffer_num: 0
        sliding_strike: 5
    head:
        num_classes: 48
        num_stages: 1
        num_layers: 4
        num_f_maps: 64
        cls_in_channels: 2048
        seg_in_channels: 2048
        sample_rate: 4
        drop_ratio: 0.5
        std: 0.001
    loss:
        seg_weight: 1.0
        cls_weight: 1.0
        ignore_index: -100

COLLATE:
    clip_seg_num: 15
    sample_rate: 4

DATASET: #DATASET field
    batch_size: 4 #Mandatory, bacth size
    num_workers: 2 #Mandatory, XXX the number of subprocess on each GPU.
    test_batch_size: 4
    train:
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/breakfast/splits/train.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/breakfast/Videos"
        gt_path: "./data/breakfast/groundTruth"
        actions_map_file_path: "./data/breakfast/mapping.txt"
        dataset_type: "breakfast"
        sliding_window: 15
        clip_seg_num: 15
        sample_rate: 4
    test:
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/breakfast/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/breakfast/Videos"
        gt_path: "./data/breakfast/groundTruth"
        actions_map_file_path: "./data/breakfast/mapping.txt"
        dataset_type: "breakfast"
        sliding_window: 15
        clip_seg_num: 15
        sample_rate: 4

PIPELINE: #PIPELINE field
    train: #Mandotary, indicate the pipeline to deal with the training data, associate to the 'paddlevideo/loader/pipelines/'
        decode:
            backend: "decord"
        sample:
            seg_len: 1
            sample_rate: 4
            clip_seg_num: 15
            sliding_window: 15
            valid_mode: False
            select_left: True
        transform: #Mandotary, image transform operator.
            - Resize:
                size: 256
            - RandomCrop:
                size: 224
            - RandomHorizontalFlip:
            - ToTensor:
            - Normalize:
                mean: [0.551, 0.424, 0.179]
                std: [0.133, 0.141, 0.124]

    test:
        decode:
            backend: "decord"
        sample:
            seg_len: 1
            sample_rate: 4
            clip_seg_num: 15
            valid_mode: True
            select_left: True
        transform:
            - Resize:
                size: 256
            - CenterCrop:
                target_size: 224
            - ToTensor:
            - Normalize:
                mean: [0.551, 0.424, 0.179]
                std: [0.133, 0.141, 0.124]

OPTIMIZER: #OPTIMIZER field
    learning_rate: 0.0001
    step_size: 50
    gamma: 0.1

METRIC:
    overlap: [.1, .25, .5]
    actions_map_file_path: "./data/breakfast/mapping.txt"
    tolerance: 5
    boundary_threshold: 0.7


model_name: "ETEMSTCN"
log_interval: 10 #Optional, the interal of logger, default:10
epochs: 50 #Mandatory, total epoch
save_interval: 10
