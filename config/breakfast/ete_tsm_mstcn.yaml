MODEL: #MODEL field
    backbone: #Mandatory, indicate the type of backbone, associate to the 'paddlevideo/modeling/backbones/' .
        name: "ResNet" #Mandatory, The name of backbone.
        pretrained: "data/ResNet50_pretrain.pdparams" #Optional, pretrained model path.
        # num_seg: 15
        depth: 50 #Optional, the depth of backbone architecture. # 层数是不是太深了
    neck:
        name: "ETENeck" # 层数多 对比层数少的分数
        buffer_channels: 512
        hidden_channels: 64
        num_layers: 5
        num_segs: 15
        clip_buffer_num: 0
        sliding_strike: 5
    head:
        name: "ETEHead" #Mandatory, indicate the type of head, associate to the 'paddlevideo/modeling/heads'
        num_classes: 48 #Optional, the number of classes to be classified.
        num_stages: 1 #Optional, the number of stages.
        num_layers: 4 # Optional, the number of layers in each stage.
        num_f_maps: 64 #Optional, the number of channels in each layers.
        in_channels: 2048  #Optional, the number of channels in input feature.
        sample_rate: 4
        drop_ratio: 0.5 #the ratio of dropout
        std: 0.001 #std value in params initialization
    seg_weight: 1.0
    val_sliding_strike: 5

MIX:
    name: "BatchCompose"
    clip_seg_num: 15
    sample_rate: 4

DATASET: #DATASET field
    batch_size: 4 #Mandatory, bacth size
    num_workers: 2 #Mandatory, XXX the number of subprocess on each GPU.
    test_batch_size: 4
    train:
        format: "SegmentationDataset" #Mandatory, indicate the type of dataset, associate to the 'paddlevidel/loader/dateset'
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/breakfast/splits/train.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/breakfast/Videos"
        gt_path: "./data/breakfast/groundTruth"
        actions_map_file_path: "./data/breakfast/mapping.txt"
        dataset_type: "breakfast"
    valid:
        format: "SegmentationDataset" #Mandatory, indicate the type of dataset, associate to the 'paddlevidel/loader/dateset'
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/breakfast/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/breakfast/Videos"
        gt_path: "./data/breakfast/groundTruth"
        actions_map_file_path: "./data/breakfast/mapping.txt"
        dataset_type: "breakfast"
    test:
        format: "SegmentationDataset" #Mandatory, indicate the type of dataset, associate to the 'paddlevidel/loader/dateset'
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/breakfast/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/breakfast/Videos"
        gt_path: "./data/breakfast/groundTruth"
        actions_map_file_path: "./data/breakfast/mapping.txt"
        dataset_type: "breakfast"

PIPELINE: #PIPELINE field
    train: #Mandotary, indicate the pipeline to deal with the training data, associate to the 'paddlevideo/loader/pipelines/'
        decode:
            name: "VideoDecoder"
            backend: "decord"
        sample:
            name: "VideoStramSampler"
            seg_len: 1
            sample_rate: 4
            valid_mode: False
            select_left: True
        transform: #Mandotary, image transform operator.
            - MultiScaleCrop:
                target_size: 224
                allow_duplication: True
            - RandomFlip:
            - Image2Array:
            - Normalization:
                mean: [0.551, 0.424, 0.179]
                std: [0.133, 0.141, 0.124]

    test:
        decode:
            name: "VideoDecoder"
            backend: "decord"
        sample:
            name: "VideoStramSampler"
            seg_len: 1
            sample_rate: 4
            valid_mode: True
            select_left: True
        transform:
            - Scale:
                short_size: 256
                fixed_ratio: False
            - CenterCrop:
                target_size: 224
            - Image2Array:
            - Normalization:
                mean: [0.551, 0.424, 0.179]
                std: [0.133, 0.141, 0.124]

OPTIMIZER: #OPTIMIZER field
    learning_rate: 0.0001
    step_size: 50
    gamma: 0.1

METRIC:
    name: 'SegmentationMetric'
    overlap: [.1, .25, .5]
    actions_map_file_path: "./data/breakfast/mapping.txt"
    tolerance: 5
    boundary_threshold: 0.7


model_name: "ETEMSTCN"
log_interval: 10 #Optional, the interal of logger, default:10
epochs: 50 #Mandatory, total epoch
save_interval: 10
