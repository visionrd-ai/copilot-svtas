MODEL:
    architecture: "SegmentationCLIP"
    image_backbone:
        architecture: "StreamSegmentation2DWithoutBackbone"
        backbone:
            name: "MobileNetV2TSM"
            pretrained: "./data/tsm_mobilenetv2_dense_320p_1x1x8_100e_kinetics400_rgb_20210202-61135809.pth"
            clip_seg_num: 32
            shift_div: 8
            out_indices: (7, )
        neck:
            name: "AvgPoolNeck"
            num_classes: 11
            in_channels: 1280
            clip_seg_num: 32
            drop_ratio: 0.5
            need_pool: True
            need_pre_cls: False
        head:
            name: "IdentityEmbeddingHead"
            sample_rate: 4
            in_channels: 1280
            out_channels: 64
    text_backbone:
        architecture: "Encoder2Decoder"
        encoder:
            name: "BridgePromptTextEncoder"
            actions_map_file_path: "./data/gtea/mapping.txt"
            embedding_dim: 512
            sample_rate: 4
            cnt_max: 11
            max_len: 100
            encoder_layers_num: 3
            encoder_heads_num: 8
            text_embed_dim: 64
        decoder:
        head:
    fusion_model:
        name: "BridgePromptFusionEarlyhyp"
        embedding_dim: 64
        clip_seg_num: 32
        num_layers: 6
        cnt_max: 11
        seg_model:
            name: "MultiStageModel"
            num_stages: 1
            num_layers: 4
            num_f_maps: 64
            dim: 64
            num_classes: 11
            sample_rate: 4
            out_feature: False
    loss:
        name: "BridgePromptCLIPSegmentationLoss"
        num_classes: 11
        sample_rate: 4
        cnt_max: 11
        img_seg_loss_weights: 1.0
        clip_loss_weight: 1.0
        ignore_index: -100

POSTPRECESSING:
    name: "StreamScorePostProcessing"
    num_classes: 11
    clip_seg_num: 32
    sliding_window: 128
    sample_rate: 4
    ignore_index: -100

COLLATE:
    name: "StreamBatchCompose"
    to_tensor_keys: ["imgs", "labels", "masks" ,"precise_sliding_num"]

DATASET: #DATASET field
    temporal_clip_batch_size: 3
    video_batch_size: 2
    num_workers: 2
    train:
        name: "RawFrameStreamSegmentationDataset"
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/gtea/splits/train.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/gtea/Videos"
        gt_path: "./data/gtea/groundTruth"
        actions_map_file_path: "./data/gtea/mapping.txt"
        dataset_type: "gtea"
        train_mode: True
        sliding_window: 128
        clip_seg_num: 32
        sample_rate: 4
    test:
        name: "RawFrameStreamSegmentationDataset"
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/gtea/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/gtea/Videos"
        gt_path: "./data/gtea/groundTruth"
        actions_map_file_path: "./data/gtea/mapping.txt"
        dataset_type: "gtea"
        train_mode: False
        sliding_window: 128
        clip_seg_num: 32
        sample_rate: 4

PIPELINE: #PIPELINE field
    train: 
        name: "BasePipline"
        decode:
            name: "VideoDecoder"
            backend: "decord"
        sample:
            name: "VideoStreamSampler"
            is_train: True
            sample_rate: 4
            clip_seg_num: 32
            sliding_window: 128
            sample_mode: "uniform"
        transform: #Mandotary, image transform operator.
            name: "VideoStreamTransform"
            transform_list:
                - Resize:
                    size: [256, 320]
                - RandomCrop:
                    size: 256
                - RandomHorizontalFlip:
                - ToTensor:
                - Normalize:
                    mean: [0.551, 0.424, 0.179]
                    std: [0.133, 0.141, 0.124]

    test:
        name: "BasePipline"
        decode:
            name: "VideoDecoder"
            backend: "decord"
        sample:
            name: "VideoStreamSampler"
            is_train: False
            sample_rate: 4
            clip_seg_num: 32
            sliding_window: 128
            sample_mode: "uniform"
        transform:
            name: "VideoStreamTransform"
            transform_list:
                - Resize:
                    size: [256, 320]
                - CenterCrop:
                    size: 256
                - ToTensor:
                - Normalize:
                    mean: [0.551, 0.424, 0.179]
                    std: [0.133, 0.141, 0.124]

OPTIMIZER:
    name: "AdamOptimizer"
    learning_rate: 0.0005
    weight_decay: 1e-4
    betas: (0.9, 0.999)

LRSCHEDULER:
    name: "MultiStepLR"
    step_size: [50]
    gamma: 0.1

METRIC:
    name: "TASegmentationMetric"
    overlap: [.1, .25, .5]
    actions_map_file_path: "./data/gtea/mapping.txt"
    file_output: True


model_name: "Bridge_Prompt_Memory_tcn_gtea_split1"
log_interval: 4 #Optional, the interal of logger, default:10
epochs: 50 #Mandatory, total epoch
save_interval: 10
