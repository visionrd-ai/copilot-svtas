MODEL:
    backbone:
        name: "ResNetTSM"
        pretrained: True
        depth: 50
        clip_seg_num: 30
        shift_div: 30
    neck:
        clip_seg_num: 30
    head:
        num_classes: 11
        num_layers: 4
        num_stages: 1
        sample_rate: 4
        sliding_window: 120
        seg_in_channels: 2048
        num_f_maps: 64
    loss:
        num_classes: 11
        sample_rate: 4
        seg_weight: 1.0
        ignore_index: -100

COLLATE:
    to_tensor_idx: 3

DATASET: #DATASET field
    temporal_clip_batch_size: 3
    video_batch_size: 2
    num_workers: 2
    train:
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/gtea/splits/train.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/gtea/Videos"
        gt_path: "./data/gtea/groundTruth"
        actions_map_file_path: "./data/gtea/mapping.txt"
        dataset_type: "gtea"
        train_mode: True
        sliding_window: 120
        clip_seg_num: 30
        sample_rate: 4
    test:
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/gtea/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/gtea/Videos"
        gt_path: "./data/gtea/groundTruth"
        actions_map_file_path: "./data/gtea/mapping.txt"
        dataset_type: "gtea"
        train_mode: False
        sliding_window: 120
        clip_seg_num: 30
        sample_rate: 4

PIPELINE: #PIPELINE field
    train: #Mandotary, indicate the pipeline to deal with the training data, associate to the 'paddlevideo/loader/pipelines/'
        decode:
            backend: "decord"
        sample:
            seg_len: 1
            sample_rate: 4
            clip_seg_num: 30
            sliding_window: 120
            sample_mode: "random"
        transform: #Mandotary, image transform operator.
            - Resize:
                size: 256
            - RandomCrop:
                size: 224
            - RandomHorizontalFlip:
            - ToTensor:
            - Normalize:
                mean: [0.551, 0.424, 0.179]
                std: [0.133, 0.141, 0.124]

    test:
        decode:
            backend: "decord"
        sample:
            seg_len: 1
            sample_rate: 4
            clip_seg_num: 30
            sliding_window: 120
            sample_mode: "uniform"
        transform:
            - Resize:
                size: 256
            - CenterCrop:
                size: 224
            - ToTensor:
            - Normalize:
                mean: [0.551, 0.424, 0.179]
                std: [0.133, 0.141, 0.124]

OPTIMIZER: #OPTIMIZER field
    learning_rate: 0.0005 # 2 gpus * 2 batch size = 4
    step_size: 50
    gamma: 0.1

METRIC:
    overlap: [.1, .25, .5]
    actions_map_file_path: "./data/gtea/mapping.txt"
    file_output: True


model_name: "ETESVS_gtea_split1"
log_interval: 2 #Optional, the interal of logger, default:10
epochs: 50 #Mandatory, total epoch
save_interval: 10
