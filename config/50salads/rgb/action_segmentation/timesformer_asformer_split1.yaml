MODEL:
    architecture: "StreamSegmentation3D"
    backbone:
        name: "TimeSformer"
        num_frames: 32
        img_size: 224
        patch_size: 32
        embed_dims: 768
        pretrained: "data/timesformer_divST_8x32x1_15e_kinetics400_rgb-3f8e5d03.pth"
    neck:
        name: "AvgPoolNeck"
        num_classes: 19
        in_channels: 768
        clip_seg_num: 32
        drop_ratio: 0.5
        need_pool: True
    head:
        name: "ASFormer"
        num_decoders: 0
        num_layers: 4
        r1: 2
        r2: 2
        num_f_maps: 64
        input_dim: 768
        num_classes: 19
        sample_rate: 20
        channel_masking_rate: 0.5
    loss:
        name: "StreamSegmentationLoss"
        num_classes: 19
        sample_rate: 20
        backone_loss_weight: 1.0
        head_loss_weight: 1.0
        ignore_index: -100

POSTPRECESSING:
    name: "StreamScorePostProcessing"
    num_classes: 19
    clip_seg_num: 32
    sliding_window: 640
    sample_rate: 20
    ignore_index: -100

COLLATE:
    name: "StreamBatchCompose"
    to_tensor_keys: ["imgs", "labels", "masks" , "precise_sliding_num"]

DATASET: #DATASET field
    temporal_clip_batch_size: 3
    video_batch_size: 2
    num_workers: 2
    train:
        name: "RawFrameSegmentationDataset"
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/50salads/splits/train.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/50salads/Videos"
        gt_path: "./data/50salads/groundTruth"
        actions_map_file_path: "./data/50salads/mapping.txt"
        dataset_type: "50salads"
        train_mode: True
        sliding_window: 640
        clip_seg_num: 32
        sample_rate: 20
    test:
        name: "RawFrameSegmentationDataset"
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/50salads/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/50salads/Videos"
        gt_path: "./data/50salads/groundTruth"
        actions_map_file_path: "./data/50salads/mapping.txt"
        dataset_type: "50salads"
        train_mode: False
        sliding_window: 640
        clip_seg_num: 32
        sample_rate: 20

PIPELINE: #PIPELINE field
    train: 
        name: "BasePipline"
        decode:
            name: "VideoDecoder"
            backend: "decord"
        sample:
            name: "VideoStreamSampler"
            is_train: True
            sample_rate: 20
            clip_seg_num: 32
            sliding_window: 640
            sample_mode: "uniform"
        transform: #Mandotary, image transform operator.
            name: "VideoStreamTransform"
            transform_list:
                - Resize:
                    size: [256, 320]
                - RandomCrop:
                    size: 224
                - RandomHorizontalFlip:
                - ToTensor:
                - Normalize:
                    mean: [0.513, 0.511, 0.479]
                    std: [0.236, 0.233, 0.237]

    test:
        name: "BasePipline"
        decode:
            name: "VideoDecoder"
            backend: "decord"
        sample:
            name: "VideoStreamSampler"
            is_train: False
            sample_rate: 20
            clip_seg_num: 32
            sliding_window: 640
            sample_mode: "uniform"
        transform:
            name: "VideoStreamTransform"
            transform_list:
                - Resize:
                    size: [256, 320]
                - CenterCrop:
                    size: 224
                - ToTensor:
                - Normalize:
                    mean: [0.513, 0.511, 0.479]
                    std: [0.236, 0.233, 0.237]

OPTIMIZER:
    name: "AdamOptimizer"
    learning_rate: 0.0005
    weight_decay: 1e-4
    betas: (0.9, 0.999)

LRSCHEDULER:
    name: "MultiStepLR"
    step_size: [50]
    gamma: 0.1

METRIC:
    name: "TASegmentationMetric"
    overlap: [.1, .25, .5]
    actions_map_file_path: "./data/50salads/mapping.txt"
    file_output: True


model_name: "TimeSformer_ASformer_50salads_split1"
log_interval: 10 #Optional, the interal of logger, default:10
epochs: 50 #Mandatory, total epoch
save_interval: 10
