MODEL:
    backbone:
        pretrained: True
        depth: 50
    neck:
        buffer_channels: 512
        hidden_channels: 64
        num_layers: 5
        clip_seg_num: 15
        clip_buffer_num: 0
        sliding_window: 60
    head:
        num_classes: 19
        num_stages: 1
        num_layers: 4
        num_f_maps: 64
        cls_in_channels: 2048
        seg_in_channels: 2048
        sample_rate: 8
        drop_ratio: 0.5
    loss:
        num_classes: 19
        sample_rate: 8
        seg_weight: 1.0
        cls_weight: 1.0
        ignore_index: -100

COLLATE:
    to_tensor_idx: 3

DATASET: #DATASET field
    temporal_clip_batch_size: 3
    video_batch_size: 2
    num_workers: 2
    train:
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/50salads/splits/train.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/50salads/Videos"
        gt_path: "./data/50salads/groundTruth"
        actions_map_file_path: "./data/50salads/mapping.txt"
        dataset_type: "50salads"
        sliding_window: 60
        clip_seg_num: 15
        sample_rate: 8
    test:
        data_prefix: "./" #Mandatory, train data root path
        file_path: "./data/50salads/splits/test.split1.bundle" #Mandatory, train data index file path
        videos_path: "./data/50salads/Videos"
        gt_path: "./data/50salads/groundTruth"
        actions_map_file_path: "./data/50salads/mapping.txt"
        dataset_type: "50salads"
        sliding_window: 60
        clip_seg_num: 15
        sample_rate: 8

PIPELINE: #PIPELINE field
    train: #Mandotary, indicate the pipeline to deal with the training data, associate to the 'paddlevideo/loader/pipelines/'
        decode:
            backend: "decord"
        sample:
            seg_len: 1
            sample_rate: 8
            clip_seg_num: 15
            sliding_window: 60
        transform: #Mandotary, image transform operator.
            - Resize:
                size: 256
            - RandomCrop:
                size: 224
            - RandomHorizontalFlip:
            - ToTensor:
            - Normalize:
                mean: [0.513, 0.511, 0.479]
                std: [0.236, 0.233, 0.237]

    test:
        decode:
            backend: "decord"
        sample:
            seg_len: 1
            sample_rate: 8
            clip_seg_num: 15
            sliding_window: 60
        transform:
            - Resize:
                size: 256
            - CenterCrop:
                size: 224
            - ToTensor:
            - Normalize:
                mean: [0.513, 0.511, 0.479]
                std: [0.236, 0.233, 0.237]

OPTIMIZER: #OPTIMIZER field
    learning_rate: 0.0005
    step_size: 50
    gamma: 0.1

METRIC:
    overlap: [.1, .25, .5]
    actions_map_file_path: "./data/50salads/mapping.txt"
    tolerance: 5
    boundary_threshold: 0.7


model_name: "ETETS_50salads_split1"
log_interval: 3 #Optional, the interal of logger, default:10
epochs: 50 #Mandatory, total epoch
save_interval: 10
